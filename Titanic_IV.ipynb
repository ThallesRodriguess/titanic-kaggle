{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d7c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a72dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Documents/CSVs/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5dd2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Documents/CSVs/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270b0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sub = pd.read_csv(\"Documents/CSVs/titanic/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce75cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9650f3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.00</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name  \\\n",
       "886          887         0       2                     Montvila, Rev. Juozas   \n",
       "887          888         1       1              Graham, Miss. Margaret Edith   \n",
       "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890         1       1                     Behr, Mr. Karl Howell   \n",
       "890          891         0       3                       Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
       "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
       "887  female  19.0      0      0      112053  30.00   B42        S  \n",
       "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
       "889    male  26.0      0      0      111369  30.00  C148        C  \n",
       "890    male  32.0      0      0      370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935ad104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275131ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f67a2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Age'].fillna(df_train['Age'].mean(), inplace=True) #AGE média\n",
    "df_test['Age'].fillna(df_test['Age'].mean(), inplace=True) #AGE média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915a7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['new_cabin'] = le.fit_transform(df_train['Cabin'].fillna('NaN'))\n",
    "df_test['new_cabin'] = le.fit_transform(df_test['Cabin'].fillna('NaN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cdc5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_idx1 = int(df_train['new_cabin'].mean())\n",
    "df_train['new_cabin'].fillna(mean_idx1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2f1d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['new_cabin'].fillna(mean_idx1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6cca382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_sexo(valor):\n",
    "    if valor == 'female':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfdf75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex_binario'] = df_train['Sex'].map(transformar_sexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74951b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Sex_binario'] = df_test['Sex'].map(transformar_sexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8addfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis = ['Sex_binario', 'Age', 'new_cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce255e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= df_train[variaveis]\n",
    "y_train= df_train['Survived']\n",
    "X_test = df_test[variaveis]  # PARTE QUE FICOU FALTANDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63135fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f73eaa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.98733297e-17 2.23290646e-16 2.59176643e-16]\n"
     ]
    }
   ],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(np.mean(X_train, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abab6338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68486580\n",
      "Iteration 2, loss = 0.65193376\n",
      "Iteration 3, loss = 0.62396171\n",
      "Iteration 4, loss = 0.59978409\n",
      "Iteration 5, loss = 0.57858182\n",
      "Iteration 6, loss = 0.56049637\n",
      "Iteration 7, loss = 0.54332052\n",
      "Iteration 8, loss = 0.52962799\n",
      "Iteration 9, loss = 0.51807962\n",
      "Iteration 10, loss = 0.50931094\n",
      "Iteration 11, loss = 0.50142064\n",
      "Iteration 12, loss = 0.49668896\n",
      "Iteration 13, loss = 0.49291633\n",
      "Iteration 14, loss = 0.49043324\n",
      "Iteration 15, loss = 0.48797840\n",
      "Iteration 16, loss = 0.48587095\n",
      "Iteration 17, loss = 0.48364848\n",
      "Iteration 18, loss = 0.48177976\n",
      "Iteration 19, loss = 0.48025087\n",
      "Iteration 20, loss = 0.47867209\n",
      "Iteration 21, loss = 0.47687238\n",
      "Iteration 22, loss = 0.47545927\n",
      "Iteration 23, loss = 0.47419764\n",
      "Iteration 24, loss = 0.47290597\n",
      "Iteration 25, loss = 0.47165431\n",
      "Iteration 26, loss = 0.47078946\n",
      "Iteration 27, loss = 0.46980643\n",
      "Iteration 28, loss = 0.46873657\n",
      "Iteration 29, loss = 0.46787938\n",
      "Iteration 30, loss = 0.46717201\n",
      "Iteration 31, loss = 0.46645968\n",
      "Iteration 32, loss = 0.46565278\n",
      "Iteration 33, loss = 0.46490388\n",
      "Iteration 34, loss = 0.46437927\n",
      "Iteration 35, loss = 0.46371948\n",
      "Iteration 36, loss = 0.46340142\n",
      "Iteration 37, loss = 0.46291247\n",
      "Iteration 38, loss = 0.46236355\n",
      "Iteration 39, loss = 0.46197783\n",
      "Iteration 40, loss = 0.46148607\n",
      "Iteration 41, loss = 0.46108650\n",
      "Iteration 42, loss = 0.46067623\n",
      "Iteration 43, loss = 0.46094424\n",
      "Iteration 44, loss = 0.46035616\n",
      "Iteration 45, loss = 0.45993511\n",
      "Iteration 46, loss = 0.45938272\n",
      "Iteration 47, loss = 0.45913798\n",
      "Iteration 48, loss = 0.45870665\n",
      "Iteration 49, loss = 0.45848538\n",
      "Iteration 50, loss = 0.45823673\n",
      "Iteration 51, loss = 0.45807913\n",
      "Iteration 52, loss = 0.45783087\n",
      "Iteration 53, loss = 0.45771168\n",
      "Iteration 54, loss = 0.45752640\n",
      "Iteration 55, loss = 0.45709061\n",
      "Iteration 56, loss = 0.45693227\n",
      "Iteration 57, loss = 0.45668985\n",
      "Iteration 58, loss = 0.45660666\n",
      "Iteration 59, loss = 0.45627846\n",
      "Iteration 60, loss = 0.45584234\n",
      "Iteration 61, loss = 0.45555711\n",
      "Iteration 62, loss = 0.45563088\n",
      "Iteration 63, loss = 0.45547541\n",
      "Iteration 64, loss = 0.45544007\n",
      "Iteration 65, loss = 0.45487486\n",
      "Iteration 66, loss = 0.45490996\n",
      "Iteration 67, loss = 0.45452814\n",
      "Iteration 68, loss = 0.45410724\n",
      "Iteration 69, loss = 0.45382882\n",
      "Iteration 70, loss = 0.45417237\n",
      "Iteration 71, loss = 0.45408957\n",
      "Iteration 72, loss = 0.45336982\n",
      "Iteration 73, loss = 0.45311741\n",
      "Iteration 74, loss = 0.45321304\n",
      "Iteration 75, loss = 0.45300576\n",
      "Iteration 76, loss = 0.45270401\n",
      "Iteration 77, loss = 0.45264321\n",
      "Iteration 78, loss = 0.45253123\n",
      "Iteration 79, loss = 0.45224110\n",
      "Iteration 80, loss = 0.45172204\n",
      "Iteration 81, loss = 0.45282353\n",
      "Iteration 82, loss = 0.45204464\n",
      "Iteration 83, loss = 0.45128696\n",
      "Iteration 84, loss = 0.45158884\n",
      "Iteration 85, loss = 0.45106367\n",
      "Iteration 86, loss = 0.45092907\n",
      "Iteration 87, loss = 0.45109700\n",
      "Iteration 88, loss = 0.45052829\n",
      "Iteration 89, loss = 0.45057011\n",
      "Iteration 90, loss = 0.45021248\n",
      "Iteration 91, loss = 0.45030618\n",
      "Iteration 92, loss = 0.45003362\n",
      "Iteration 93, loss = 0.44980190\n",
      "Iteration 94, loss = 0.44972428\n",
      "Iteration 95, loss = 0.44978229\n",
      "Iteration 96, loss = 0.44979843\n",
      "Iteration 97, loss = 0.44949146\n",
      "Iteration 98, loss = 0.44929223\n",
      "Iteration 99, loss = 0.44960977\n",
      "Iteration 100, loss = 0.44891047\n",
      "Iteration 101, loss = 0.44892089\n",
      "Iteration 102, loss = 0.44898454\n",
      "Iteration 103, loss = 0.44861821\n",
      "Iteration 104, loss = 0.44834518\n",
      "Iteration 105, loss = 0.44830171\n",
      "Iteration 106, loss = 0.44843099\n",
      "Iteration 107, loss = 0.44845054\n",
      "Iteration 108, loss = 0.44779200\n",
      "Iteration 109, loss = 0.44789160\n",
      "Iteration 110, loss = 0.44760839\n",
      "Iteration 111, loss = 0.44781228\n",
      "Iteration 112, loss = 0.44765968\n",
      "Iteration 113, loss = 0.44806714\n",
      "Iteration 114, loss = 0.44765649\n",
      "Iteration 115, loss = 0.44753237\n",
      "Iteration 116, loss = 0.44716027\n",
      "Iteration 117, loss = 0.44696388\n",
      "Iteration 118, loss = 0.44688887\n",
      "Iteration 119, loss = 0.44691960\n",
      "Iteration 120, loss = 0.44692908\n",
      "Iteration 121, loss = 0.44651716\n",
      "Iteration 122, loss = 0.44653789\n",
      "Iteration 123, loss = 0.44648535\n",
      "Iteration 124, loss = 0.44635366\n",
      "Iteration 125, loss = 0.44629724\n",
      "Iteration 126, loss = 0.44682462\n",
      "Iteration 127, loss = 0.44612861\n",
      "Iteration 128, loss = 0.44656286\n",
      "Iteration 129, loss = 0.44615514\n",
      "Iteration 130, loss = 0.44578816\n",
      "Iteration 131, loss = 0.44574712\n",
      "Iteration 132, loss = 0.44567597\n",
      "Iteration 133, loss = 0.44550135\n",
      "Iteration 134, loss = 0.44542257\n",
      "Iteration 135, loss = 0.44520177\n",
      "Iteration 136, loss = 0.44523596\n",
      "Iteration 137, loss = 0.44531433\n",
      "Iteration 138, loss = 0.44491038\n",
      "Iteration 139, loss = 0.44479162\n",
      "Iteration 140, loss = 0.44473450\n",
      "Iteration 141, loss = 0.44468110\n",
      "Iteration 142, loss = 0.44487900\n",
      "Iteration 143, loss = 0.44494323\n",
      "Iteration 144, loss = 0.44470307\n",
      "Iteration 145, loss = 0.44453344\n",
      "Iteration 146, loss = 0.44436744\n",
      "Iteration 147, loss = 0.44422965\n",
      "Iteration 148, loss = 0.44412785\n",
      "Iteration 149, loss = 0.44425644\n",
      "Iteration 150, loss = 0.44394460\n",
      "Iteration 151, loss = 0.44443854\n",
      "Iteration 152, loss = 0.44404262\n",
      "Iteration 153, loss = 0.44385505\n",
      "Iteration 154, loss = 0.44392330\n",
      "Iteration 155, loss = 0.44381927\n",
      "Iteration 156, loss = 0.44361098\n",
      "Iteration 157, loss = 0.44357662\n",
      "Iteration 158, loss = 0.44361383\n",
      "Iteration 159, loss = 0.44335721\n",
      "Iteration 160, loss = 0.44325755\n",
      "Iteration 161, loss = 0.44336868\n",
      "Iteration 162, loss = 0.44327912\n",
      "Iteration 163, loss = 0.44304194\n",
      "Iteration 164, loss = 0.44371871\n",
      "Iteration 165, loss = 0.44305308\n",
      "Iteration 166, loss = 0.44309420\n",
      "Iteration 167, loss = 0.44308301\n",
      "Iteration 168, loss = 0.44311968\n",
      "Iteration 169, loss = 0.44307745\n",
      "Iteration 170, loss = 0.44273627\n",
      "Iteration 171, loss = 0.44251097\n",
      "Iteration 172, loss = 0.44251328\n",
      "Iteration 173, loss = 0.44301409\n",
      "Iteration 174, loss = 0.44213521\n",
      "Iteration 175, loss = 0.44337434\n",
      "Iteration 176, loss = 0.44247824\n",
      "Iteration 177, loss = 0.44259745\n",
      "Iteration 178, loss = 0.44228256\n",
      "Iteration 179, loss = 0.44185176\n",
      "Iteration 180, loss = 0.44183108\n",
      "Iteration 181, loss = 0.44191966\n",
      "Iteration 182, loss = 0.44213662\n",
      "Iteration 183, loss = 0.44171431\n",
      "Iteration 184, loss = 0.44185178\n",
      "Iteration 185, loss = 0.44238018\n",
      "Iteration 186, loss = 0.44187165\n",
      "Iteration 187, loss = 0.44143662\n",
      "Iteration 188, loss = 0.44170100\n",
      "Iteration 189, loss = 0.44163918\n",
      "Iteration 190, loss = 0.44102787\n",
      "Iteration 191, loss = 0.44161346\n",
      "Iteration 192, loss = 0.44148875\n",
      "Iteration 193, loss = 0.44120321\n",
      "Iteration 194, loss = 0.44189864\n",
      "Iteration 195, loss = 0.44108454\n",
      "Iteration 196, loss = 0.44117039\n",
      "Iteration 197, loss = 0.44091464\n",
      "Iteration 198, loss = 0.44105978\n",
      "Iteration 199, loss = 0.44075484\n",
      "Iteration 200, loss = 0.44066705\n",
      "Iteration 201, loss = 0.44087324\n",
      "Iteration 202, loss = 0.44175911\n",
      "Iteration 203, loss = 0.44112883\n",
      "Iteration 204, loss = 0.44066951\n",
      "Iteration 205, loss = 0.44062846\n",
      "Iteration 206, loss = 0.44097287\n",
      "Iteration 207, loss = 0.44063068\n",
      "Iteration 208, loss = 0.44030222\n",
      "Iteration 209, loss = 0.44036704\n",
      "Iteration 210, loss = 0.44031823\n",
      "Iteration 211, loss = 0.44061200\n",
      "Iteration 212, loss = 0.44006281\n",
      "Iteration 213, loss = 0.44019561\n",
      "Iteration 214, loss = 0.43996367\n",
      "Iteration 215, loss = 0.44002335\n",
      "Iteration 216, loss = 0.43968184\n",
      "Iteration 217, loss = 0.44005415\n",
      "Iteration 218, loss = 0.43982369\n",
      "Iteration 219, loss = 0.43990034\n",
      "Iteration 220, loss = 0.44004350\n",
      "Iteration 221, loss = 0.43950202\n",
      "Iteration 222, loss = 0.43945287\n",
      "Iteration 223, loss = 0.43955666\n",
      "Iteration 224, loss = 0.43956361\n",
      "Iteration 225, loss = 0.43965678\n",
      "Iteration 226, loss = 0.43929485\n",
      "Iteration 227, loss = 0.43934118\n",
      "Iteration 228, loss = 0.43924519\n",
      "Iteration 229, loss = 0.43920407\n",
      "Iteration 230, loss = 0.43941184\n",
      "Iteration 231, loss = 0.43928447\n",
      "Iteration 232, loss = 0.43871742\n",
      "Iteration 233, loss = 0.43911887\n",
      "Iteration 234, loss = 0.43938228\n",
      "Iteration 235, loss = 0.43889935\n",
      "Iteration 236, loss = 0.43918701\n",
      "Iteration 237, loss = 0.43900950\n",
      "Iteration 238, loss = 0.43861219\n",
      "Iteration 239, loss = 0.43874012\n",
      "Iteration 240, loss = 0.43896859\n",
      "Iteration 241, loss = 0.43859319\n",
      "Iteration 242, loss = 0.43888687\n",
      "Iteration 243, loss = 0.43902657\n",
      "Iteration 244, loss = 0.43869031\n",
      "Iteration 245, loss = 0.43821254\n",
      "Iteration 246, loss = 0.43901098\n",
      "Iteration 247, loss = 0.43895988\n",
      "Iteration 248, loss = 0.43818391\n",
      "Iteration 249, loss = 0.43825792\n",
      "Iteration 250, loss = 0.43833171\n",
      "Iteration 251, loss = 0.43823496\n",
      "Iteration 252, loss = 0.43794820\n",
      "Iteration 253, loss = 0.43817097\n",
      "Iteration 254, loss = 0.43836661\n",
      "Iteration 255, loss = 0.43804733\n",
      "Iteration 256, loss = 0.43837901\n",
      "Iteration 257, loss = 0.43789762\n",
      "Iteration 258, loss = 0.43819529\n",
      "Iteration 259, loss = 0.43834552\n",
      "Iteration 260, loss = 0.43756270\n",
      "Iteration 261, loss = 0.43786015\n",
      "Iteration 262, loss = 0.43820138\n",
      "Iteration 263, loss = 0.43769728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 264, loss = 0.43740278\n",
      "Iteration 265, loss = 0.43785278\n",
      "Iteration 266, loss = 0.43825620\n",
      "Iteration 267, loss = 0.43786468\n",
      "Iteration 268, loss = 0.43756372\n",
      "Iteration 269, loss = 0.43756819\n",
      "Iteration 270, loss = 0.43750336\n",
      "Iteration 271, loss = 0.43723476\n",
      "Iteration 272, loss = 0.43787363\n",
      "Iteration 273, loss = 0.43783719\n",
      "Iteration 274, loss = 0.43740847\n",
      "Iteration 275, loss = 0.43746965\n",
      "Iteration 276, loss = 0.43707658\n",
      "Iteration 277, loss = 0.43749747\n",
      "Iteration 278, loss = 0.43720889\n",
      "Iteration 279, loss = 0.43726240\n",
      "Iteration 280, loss = 0.43756930\n",
      "Iteration 281, loss = 0.43682586\n",
      "Iteration 282, loss = 0.43727462\n",
      "Iteration 283, loss = 0.43669275\n",
      "Iteration 284, loss = 0.43702077\n",
      "Iteration 285, loss = 0.43682096\n",
      "Iteration 286, loss = 0.43698895\n",
      "Iteration 287, loss = 0.43717713\n",
      "Iteration 288, loss = 0.43702490\n",
      "Iteration 289, loss = 0.43663209\n",
      "Iteration 290, loss = 0.43680759\n",
      "Iteration 291, loss = 0.43713373\n",
      "Iteration 292, loss = 0.43713241\n",
      "Iteration 293, loss = 0.43628741\n",
      "Iteration 294, loss = 0.43671526\n",
      "Iteration 295, loss = 0.43636776\n",
      "Iteration 296, loss = 0.43704103\n",
      "Iteration 297, loss = 0.43631716\n",
      "Iteration 298, loss = 0.43677846\n",
      "Iteration 299, loss = 0.43705300\n",
      "Iteration 300, loss = 0.43635781\n",
      "Iteration 301, loss = 0.43591959\n",
      "Iteration 302, loss = 0.43604482\n",
      "Iteration 303, loss = 0.43584285\n",
      "Iteration 304, loss = 0.43604650\n",
      "Iteration 305, loss = 0.43599154\n",
      "Iteration 306, loss = 0.43566804\n",
      "Iteration 307, loss = 0.43586114\n",
      "Iteration 308, loss = 0.43574694\n",
      "Iteration 309, loss = 0.43563746\n",
      "Iteration 310, loss = 0.43579336\n",
      "Iteration 311, loss = 0.43585594\n",
      "Iteration 312, loss = 0.43578276\n",
      "Iteration 313, loss = 0.43558191\n",
      "Iteration 314, loss = 0.43551035\n",
      "Iteration 315, loss = 0.43564270\n",
      "Iteration 316, loss = 0.43533802\n",
      "Iteration 317, loss = 0.43637472\n",
      "Iteration 318, loss = 0.43582693\n",
      "Iteration 319, loss = 0.43516065\n",
      "Iteration 320, loss = 0.43558938\n",
      "Iteration 321, loss = 0.43574141\n",
      "Iteration 322, loss = 0.43560250\n",
      "Iteration 323, loss = 0.43535198\n",
      "Iteration 324, loss = 0.43591226\n",
      "Iteration 325, loss = 0.43503855\n",
      "Iteration 326, loss = 0.43484222\n",
      "Iteration 327, loss = 0.43534022\n",
      "Iteration 328, loss = 0.43492591\n",
      "Iteration 329, loss = 0.43488013\n",
      "Iteration 330, loss = 0.43500210\n",
      "Iteration 331, loss = 0.43495679\n",
      "Iteration 332, loss = 0.43505166\n",
      "Iteration 333, loss = 0.43478804\n",
      "Iteration 334, loss = 0.43498738\n",
      "Iteration 335, loss = 0.43478196\n",
      "Iteration 336, loss = 0.43439599\n",
      "Iteration 337, loss = 0.43464601\n",
      "Iteration 338, loss = 0.43470670\n",
      "Iteration 339, loss = 0.43480693\n",
      "Iteration 340, loss = 0.43475351\n",
      "Iteration 341, loss = 0.43447332\n",
      "Iteration 342, loss = 0.43421326\n",
      "Iteration 343, loss = 0.43430848\n",
      "Iteration 344, loss = 0.43474549\n",
      "Iteration 345, loss = 0.43439877\n",
      "Iteration 346, loss = 0.43394817\n",
      "Iteration 347, loss = 0.43400802\n",
      "Iteration 348, loss = 0.43411134\n",
      "Iteration 349, loss = 0.43471967\n",
      "Iteration 350, loss = 0.43399106\n",
      "Iteration 351, loss = 0.43444718\n",
      "Iteration 352, loss = 0.43419289\n",
      "Iteration 353, loss = 0.43430536\n",
      "Iteration 354, loss = 0.43416659\n",
      "Iteration 355, loss = 0.43389586\n",
      "Iteration 356, loss = 0.43373743\n",
      "Iteration 357, loss = 0.43354059\n",
      "Iteration 358, loss = 0.43357608\n",
      "Iteration 359, loss = 0.43379240\n",
      "Iteration 360, loss = 0.43389186\n",
      "Iteration 361, loss = 0.43413800\n",
      "Iteration 362, loss = 0.43341949\n",
      "Iteration 363, loss = 0.43344293\n",
      "Iteration 364, loss = 0.43433145\n",
      "Iteration 365, loss = 0.43421873\n",
      "Iteration 366, loss = 0.43371432\n",
      "Iteration 367, loss = 0.43336463\n",
      "Iteration 368, loss = 0.43337536\n",
      "Iteration 369, loss = 0.43316520\n",
      "Iteration 370, loss = 0.43338632\n",
      "Iteration 371, loss = 0.43320530\n",
      "Iteration 372, loss = 0.43343411\n",
      "Iteration 373, loss = 0.43359530\n",
      "Iteration 374, loss = 0.43317375\n",
      "Iteration 375, loss = 0.43353702\n",
      "Iteration 376, loss = 0.43307648\n",
      "Iteration 377, loss = 0.43281113\n",
      "Iteration 378, loss = 0.43301177\n",
      "Iteration 379, loss = 0.43273888\n",
      "Iteration 380, loss = 0.43270508\n",
      "Iteration 381, loss = 0.43313155\n",
      "Iteration 382, loss = 0.43250478\n",
      "Iteration 383, loss = 0.43335049\n",
      "Iteration 384, loss = 0.43318343\n",
      "Iteration 385, loss = 0.43333992\n",
      "Iteration 386, loss = 0.43308188\n",
      "Iteration 387, loss = 0.43295648\n",
      "Iteration 388, loss = 0.43292349\n",
      "Iteration 389, loss = 0.43307982\n",
      "Iteration 390, loss = 0.43392543\n",
      "Iteration 391, loss = 0.43278424\n",
      "Iteration 392, loss = 0.43306051\n",
      "Iteration 393, loss = 0.43254408\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(20, 100), max_iter=1000, tol=1e-05,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "rede_neural = MLPClassifier(max_iter=1000, \n",
    "                                   verbose=True, \n",
    "                                   tol=0.0000100,\n",
    "                                   hidden_layer_sizes=(20,100))\n",
    "\n",
    "# rede_neural = MLPClassifier(max_iter=2000, \n",
    "#                             verbose=True, \n",
    "#                             tol=1e-05,\n",
    "#                             hidden_layer_sizes=(50,100))\n",
    "\n",
    "# rede_neural = MLPClassifier(max_iter=500, \n",
    "#                             verbose=True, \n",
    "#                             tol=1e-06,\n",
    "#                             hidden_layer_sizes=(20,50))\n",
    "\n",
    "\n",
    "rede_neural.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bccc14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_previsoes = rede_neural.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aa19664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418,)\n"
     ]
    }
   ],
   "source": [
    "print(n_previsoes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eaf9fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7bafeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70f77a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rede Neural Accuracy: 0.9425837320574163\n"
     ]
    }
   ],
   "source": [
    "y_test_sub = df_test_sub['Survived']\n",
    "print(f\"Rede Neural Accuracy: {accuracy_score(y_test_sub, n_previsoes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c590873",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.Series(n_previsoes, index=df_test[\"PassengerId\"], name=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5521d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submitMI.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b5c3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Define the parameter combinations to test\n",
    "# hidden_layer_sizes_list = [(20,), (50,), (100,), (20, 50), (50, 100), (100, 200)]\n",
    "# max_iter_list = [500, 1000, 2000, 3000, 4000]\n",
    "# tol_list = [0.0001, 0.00001, 0.000001]\n",
    "\n",
    "# # Initialize variables for the best parameter values and accuracy\n",
    "# best_hidden_layer_sizes = None\n",
    "# best_max_iter = None\n",
    "# best_tol = None\n",
    "# best_accuracy = 0\n",
    "\n",
    "# # Loop through all parameter combinations\n",
    "# for hidden_layer_sizes in hidden_layer_sizes_list:\n",
    "#     for max_iter in max_iter_list:\n",
    "#         for tol in tol_list:\n",
    "#             # Create and train the MLPClassifier with the current parameters\n",
    "#             rede_neural = MLPClassifier(max_iter=max_iter, \n",
    "#                                         verbose=True, \n",
    "#                                         tol=tol,\n",
    "#                                         hidden_layer_sizes=hidden_layer_sizes)\n",
    "#             rede_neural.fit(X_train, y_train)\n",
    "\n",
    "#             # Make predictions and calculate the accuracy\n",
    "#             n_previsoes = rede_neural.predict(X_test)\n",
    "#             accuracy = accuracy_score(y_test_sub, n_previsoes)\n",
    "\n",
    "#             # Check if the current accuracy is the highest so far\n",
    "#             if accuracy > best_accuracy:\n",
    "#                 best_hidden_layer_sizes = hidden_layer_sizes\n",
    "#                 best_max_iter = max_iter\n",
    "#                 best_tol = tol\n",
    "#                 best_accuracy = accuracy\n",
    "\n",
    "# # Print the best parameter values and accuracy\n",
    "# print(\"Best parameters:\")\n",
    "# print(f\"hidden_layer_sizes: {best_hidden_layer_sizes}\")\n",
    "# print(f\"max_iter: {best_max_iter}\")\n",
    "# print(f\"tol: {best_tol}\")\n",
    "# print(f\"Best accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d0639d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_sub = df_test_sub['Survived']\n",
    "# print(f\"Rede Neural Accuracy: {accuracy_score(y_test_sub, n_previsoes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d545d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub2=pd.Series(n_previsoes, index=df_test[\"PassengerId\"], name=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d39833c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub2.to_csv(\"submitMII.csv\", header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
